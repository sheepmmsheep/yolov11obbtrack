import streamlit as st
import cv2
from ultralytics import YOLO
from streamlit_webrtc import webrtc_streamer, WebRtcMode
import av
import numpy as np

# åŠ è½½ YOLO æ¨¡å‹
model_path = "best.pt"  # æ›¿æ¢ä¸ºä½ çš„æ¨¡å‹è·¯å¾„
model = YOLO(model_path)

# Streamlit é¡µé¢æ ‡é¢˜
st.title("YOLO å®æ—¶è¿½è¸ª with YOLO.track")
st.sidebar.title("æ“ä½œé€‰é¡¹")

# ä¿¡å¿ƒé˜ˆå€¼å’Œ IOU é˜ˆå€¼
conf_threshold = st.sidebar.slider("è®¾ç½®ä¿¡å¿ƒé˜ˆå€¼", min_value=0.0, max_value=1.0, value=0.35, step=0.05)
iou_threshold = st.sidebar.slider("è®¾ç½®IOUé˜ˆå€¼", min_value=0.0, max_value=1.0, value=0.3, step=0.05)

# å®šä¹‰è§†é¢‘å¤„ç†å‡½æ•°
def video_frame_callback(frame: av.VideoFrame) -> av.VideoFrame:
    """å¤„ç†æ‘„åƒå¤´çš„æ¯ä¸€å¸§å½±åƒ"""
    img = frame.to_ndarray(format="bgr24")  # è½¬æ¢ä¸º OpenCV æ ¼å¼

    # ä½¿ç”¨ YOLO.track è¿›è¡Œè·Ÿè¸ª
    results = model.track(source=img, conf=conf_threshold, iou=iou_threshold, persist=True)

    # ç»˜åˆ¶æ£€æµ‹æ¡†
    annotated_img = results[0].plot()

    # è¿”å›å¸¦æœ‰æ£€æµ‹æ¡†çš„å½±åƒ
    return av.VideoFrame.from_ndarray(annotated_img, format="bgr24")

# å¯åŠ¨ WebRTC
webrtc_ctx = webrtc_streamer(
    key="yolo-tracking",  # å”¯ä¸€æ ‡è¯†ç¬¦
    mode=WebRtcMode.SENDRECV,  # åŒå‘æ¨¡å¼ï¼ˆæ¥æ”¶è§†é¢‘å¹¶å¤„ç†åè¿”å›ï¼‰
    video_frame_callback=video_frame_callback,  # è§†é¢‘å¤„ç†å›è°ƒ
    media_stream_constraints={"video": True, "audio": False},  # å¯ç”¨è§†é¢‘è¾“å…¥ï¼Œç¦ç”¨éŸ³é¢‘
    async_processing=True,  # å¯ç”¨å¼‚æ­¥å¤„ç†
)

# æ˜¾ç¤ºçŠ¶æ€ä¿¡æ¯
if webrtc_ctx.state.playing:
    st.markdown("### æ­£åœ¨å®æ—¶è¿½è¸ªä¸­... ğŸ”")
    st.markdown("**è¯·ç¡®ä¿æ‘„åƒå¤´å·²å¯ç”¨å¹¶æ­£å¯¹åœºæ™¯ã€‚**")
else:
    st.markdown("### ç‚¹å‡»ä¸Šæ–¹æŒ‰é’®å¯åŠ¨å®æ—¶è¿½è¸ªï¼")
