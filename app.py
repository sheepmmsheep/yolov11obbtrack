import streamlit as st
import cv2
from ultralytics import YOLO
from streamlit_webrtc import webrtc_streamer, WebRtcMode
import av
import numpy as np

# åŠ è¼‰ YOLO æ¨¡å‹
model_path = "best.pt"
model = YOLO(model_path)

# Streamlit é é¢æ¨™é¡Œ
st.title("YOLO å¯¦æ™‚è¿½è¹¤ with Streamlit-WebRTC")
st.sidebar.title("æ“ä½œé¸é …")

# ä¿¡å¿ƒé–¾å€¼ (Confidence Threshold)
conf_threshold = st.sidebar.slider("è¨­å®šä¿¡å¿ƒé–¾å€¼", min_value=0.0, max_value=1.0, value=0.35, step=0.05)
# IOU é–¾å€¼
iou_threshold = st.sidebar.slider("è¨­å®šIOUé–¾å€¼", min_value=0.0, max_value=1.0, value=0.3, step=0.05)

# å®šç¾©å½±åƒè™•ç†å›èª¿å‡½æ•¸
def video_frame_callback(frame: av.VideoFrame) -> av.VideoFrame:
    """è™•ç†æ”åƒé ­çš„æ¯ä¸€å¹€å½±åƒ"""
    # è½‰æ›å½±åƒç‚º OpenCV æ ¼å¼
    img = frame.to_ndarray(format="bgr24")

    # YOLO æ¨¡å‹æ¨ç†
    results = model.predict(source=img, conf=conf_threshold, iou=iou_threshold, agnostic_nms=True)

    # ç¹ªè£½æª¢æ¸¬æ¡†
    annotated_img = results[0].plot()

    # è¿”å›å¸¶æœ‰æª¢æ¸¬æ¡†çš„å½±åƒ
    return av.VideoFrame.from_ndarray(annotated_img, format="bgr24")

# å•Ÿå‹• WebRTC
webrtc_ctx = webrtc_streamer(
    key="yolo-tracking",  # å”¯ä¸€æ¨™è­˜ç¬¦
    mode=WebRtcMode.SENDRECV,  # é›™å‘æ¨¡å¼ï¼ˆæ¥æ”¶è¦–é »ä¸¦è™•ç†å¾Œè¿”å›ï¼‰
    video_frame_callback=video_frame_callback,  # è™•ç†å›èª¿
    media_stream_constraints={"video": True, "audio": False},  # å•Ÿç”¨è¦–é »è¼¸å…¥ï¼Œç¦ç”¨éŸ³é »
    async_processing=True,  # å•Ÿç”¨éåŒæ­¥è™•ç†
)

# å¦‚æœ WebRTC æ­£åœ¨æ’­æ”¾ï¼Œé¡¯ç¤ºæç¤º
if webrtc_ctx.state.playing:
    st.markdown("### æ­£åœ¨å¯¦æ™‚è¿½è¹¤ä¸­... ğŸ”")
    st.markdown("**è«‹ç¢ºä¿æ”å½±é¡é ­å·²å•Ÿç”¨ä¸¦æ­£å°å ´æ™¯**ã€‚")
else:
    st.markdown("### é»æ“Šä¸Šæ–¹æŒ‰éˆ•å•Ÿå‹•å¯¦æ™‚è¿½è¹¤ï¼")
